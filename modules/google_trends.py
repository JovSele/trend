"""
Google Trends Modul - S Webshare.io Proxy Podporou
===================================================

Analyzuje trhov√Ω dopyt pomocou Google Trends API cez proxy.
"""

from pytrends.request import TrendReq
import time
import re
import pandas as pd
import numpy as np
from typing import List, Dict, Optional
import os
from dotenv import load_dotenv

# Naƒç√≠tanie .env
load_dotenv()


class GoogleTrendsAnalyzer:
    """Analyzer pre Google Trends s proxy podporou"""
    
    def __init__(self, language='en-US', timezone=360, use_proxy=True):
        """
        Args:
            language: Jazyk (en-US, sk-SK, ...)
            timezone: ƒåasov√° z√≥na (360 = GMT+6)
            use_proxy: Pou≈æi≈• Webshare.io proxy (True = odpor√∫ƒçan√©)
        """
        proxies = None
        
        # Konfigur√°cia proxy z .env
        if use_proxy:
            proxy_user = os.getenv('WEBSHARE_PROXY_USER')
            proxy_pass = os.getenv('WEBSHARE_PROXY_PASS')
            proxy_host = os.getenv('WEBSHARE_PROXY_HOST')
            proxy_port = os.getenv('WEBSHARE_PROXY_PORT')
            
            if all([proxy_user, proxy_pass, proxy_host, proxy_port]):
                # pytrends oƒçak√°va proxy ako LIST, nie dict!
                proxy_url = f"http://{proxy_user}:{proxy_pass}@{proxy_host}:{proxy_port}"
                proxies = [proxy_url]  # ‚Üê ZMENA: list namiesto dict
                print("üîí Proxy AKTIVOVAN√â (Webshare.io)")
                print(f"   Proxy: {proxy_host}:{proxy_port}")
            else:
                print("‚ö†Ô∏è  Proxy credentials nen√°jden√© v .env")
                print("   Pokraƒçujem BEZ proxy (m√¥≈æe by≈• blokovan√©)")
        
        # Inicializ√°cia pytrends s proxy
        self.pytrends = TrendReq(
            hl=language, 
            tz=timezone, 
            timeout=(10, 25),
            proxies=proxies  # ‚Üê LIST form√°t
        )
        self.cache = {}
        self.use_proxy = use_proxy and proxies is not None
        
    def analyze_patent(self, title: str, abstract: str = None, 
                      timeframe: str = 'today 5-y') -> Dict:
        """
        Analyzuje jeden patent a vr√°ti Trends score
        
        Args:
            title: N√°zov patentu
            abstract: Abstrakt (nepou≈æ√≠va sa v jednoduchej verzii)
            timeframe: 'today 5-y', 'today 3-y', 'today 12-m'
            
        Returns:
            {
                'keyword': str,
                'avg_interest': float (0-100),
                'trend_direction': str ('rising', 'stable', 'falling'),
                'final_score': float (0-1) normalized
            }
        """
        # Extrakcia kƒæ√∫ƒçov√©ho slova z n√°zvu
        keyword = self._extract_keyword(title)
        
        if not keyword:
            return self._empty_result()
        
        # Sk√∫sime z√≠ska≈• trend data
        trend_data = self._get_trends_data(keyword, timeframe)
        
        if trend_data is None or len(trend_data) == 0:
            return self._empty_result()
        
        # V√Ωpoƒçet metr√≠k
        avg_interest = trend_data['interest'].mean()
        trend_direction = self._calculate_trend_direction(trend_data)
        
        # Normaliz√°cia na 0-1
        final_score = self._normalize_score(avg_interest, trend_direction)
        
        return {
            'keyword': keyword,
            'avg_interest': avg_interest,
            'trend_direction': trend_direction,
            'final_score': final_score
        }
    
    def _extract_keyword(self, title: str) -> str:
        """
        Extrahuje hlavn√© kƒæ√∫ƒçov√© slovo z n√°zvu patentu
        
        Strat√©gia:
        1. Odstr√°ni ≈°peci√°lne znaky
        2. Vezme prv√© 3-5 slov (alebo cel√Ω n√°zov ak je kr√°tky)
        3. Vr√°ti ako vyhƒæad√°vac√≠ term
        """
        if not title or pd.isna(title):
            return ""
        
        # ƒåistenie
        title = str(title)
        title = re.sub(r'[^\w\s-]', '', title)  # Odstr√°ni ≈°peci√°lne znaky
        
        # Stop words na odstr√°nenie
        stop_words = {
            'method', 'system', 'apparatus', 'device', 'process',
            'means', 'assembly', 'composition', 'compound',
            'a', 'an', 'the', 'and', 'or', 'for', 'with', 'using'
        }
        
        words = title.lower().split()
        words = [w for w in words if w not in stop_words and len(w) > 2]
        
        # Ak je n√°zov veƒæmi kr√°tky, pou≈æijeme ho cel√Ω
        if len(title.split()) <= 5:
            return title.strip()[:100]  # Max 100 znakov
        
        # Inak vezmeme prv√© 3-4 relevantn√© slov√°
        keyword = ' '.join(words[:4])
        return keyword[:100] if keyword else title[:100]
    
    def _get_trends_data(self, keyword: str, timeframe: str) -> Optional[pd.DataFrame]:
        """
        Z√≠ska trend data z Google Trends s error handling a retry logikou
        
        Args:
            keyword: Vyhƒæad√°vac√≠ term
            timeframe: ƒåasov√© obdobie
            
        Returns:
            DataFrame s interest_over_time alebo None
        """
        # Kontrola cache
        cache_key = f"{keyword}_{timeframe}"
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # Sk√∫sime 3 razy s rast√∫cou pauzou
        for attempt in range(3):
            try:
                # Krat≈°ia pauza ak pou≈æ√≠vame proxy (1-3s), dlh≈°ia bez proxy (3-6s)
                import random
                wait_time = random.uniform(10, 20) if self.use_proxy else random.uniform(3, 6)
                
                if attempt > 0:
                    print(f"      Pokus {attempt + 1}/3...")
                time.sleep(wait_time)
                
                # Build payload pre Google Trends
                self.pytrends.build_payload(
                    [keyword],
                    cat=0,           # V≈°etky kateg√≥rie
                    timeframe=timeframe,
                    geo='',          # Worldwide
                    gprop=''         # Web search
                )
                
                # Z√≠skanie d√°t
                interest_df = self.pytrends.interest_over_time()
                
                if interest_df.empty:
                    print(f"   ‚ö†Ô∏è  ≈Ωiadne data pre: '{keyword}'")
                    return None
                
                # Premenujeme stƒ∫pec na 'interest'
                if keyword in interest_df.columns:
                    interest_df['interest'] = interest_df[keyword]
                else:
                    return None
                
                # Cache
                self.cache[cache_key] = interest_df
                
                return interest_df
                
            except Exception as e:
                error_msg = str(e)
                
                # Ak je to rate limit, poƒçk√°me dlh≈°ie
                if '429' in error_msg or 'rate limit' in error_msg.lower():
                    wait = (attempt + 1) * 30  # 30s, 60s, 90s
                    print(f"   ‚ö†Ô∏è  Rate limit! ƒåak√°m {wait}s...")
                    time.sleep(wait)
                    continue
                
                # In√© chyby
                if attempt == 2:  # Posledn√Ω pokus
                    print(f"   ‚ö†Ô∏è  Zlyhalo pre '{keyword}': {error_msg[:60]}")
                    return None
        
        return None
    
    def _calculate_trend_direction(self, trend_data: pd.DataFrame) -> str:
        """
        Vypoƒç√≠ta smer trendu (rising/stable/falling)
        
        Porovn√°va prv√∫ a druh√∫ polovicu ƒçasov√©ho obdobia
        """
        if trend_data is None or len(trend_data) < 10:
            return 'unknown'
        
        mid = len(trend_data) // 2
        first_half = trend_data['interest'].iloc[:mid].mean()
        second_half = trend_data['interest'].iloc[mid:].mean()
        
        if first_half == 0:
            return 'stable'
        
        change_pct = ((second_half - first_half) / first_half) * 100
        
        if change_pct > 25:
            return 'rising'
        elif change_pct < -25:
            return 'falling'
        else:
            return 'stable'
    
    def _normalize_score(self, avg_interest: float, trend_direction: str) -> float:
        """
        Normalizuje score na 0-1 s bonusom za rising trend
        
        Args:
            avg_interest: Priemern√Ω z√°ujem (0-100)
            trend_direction: 'rising', 'stable', 'falling'
            
        Returns:
            Normalized score (0-1)
        """
        # Base score
        base = avg_interest / 100.0
        
        # Bonus/penaliz√°cia
        if trend_direction == 'rising':
            multiplier = 1.3  # +30% bonus
        elif trend_direction == 'falling':
            multiplier = 0.7  # -30% penaliz√°cia
        else:
            multiplier = 1.0
        
        final = base * multiplier
        
        # Clamp 0-1
        return min(max(final, 0.0), 1.0)
    
    def _empty_result(self) -> Dict:
        """Pr√°zdny v√Ωsledok ak zlyh√°"""
        return {
            'keyword': '',
            'avg_interest': 0.0,
            'trend_direction': 'unknown',
            'final_score': 0.0
        }
    
    def batch_analyze(self, patents_df: pd.DataFrame, 
                     title_col: str, abstract_col: str = None,
                     batch_size: int = 10, delay_between_batches: int = 60) -> pd.DataFrame:
        """
        Analyzuje viacero patentov v d√°vkach
        
        Args:
            patents_df: DataFrame s patentmi
            title_col: N√°zov stƒ∫pca s titulkom
            abstract_col: N√°zov stƒ∫pca s abstraktom (nepou≈æ√≠va sa)
            batch_size: Poƒçet patentov v d√°vke
            delay_between_batches: Pauza medzi d√°vkami (sekundy)
            
        Returns:
            DataFrame s pridan√Ωmi stƒ∫pcami:
            - Google_Trends_Score (0-1 normalized)
            - Google_Trends_Keyword
            - Google_Trends_Direction
            - Google_Trends_Avg_Interest (0-100)
        """
        total = len(patents_df)
        
        print(f"\nüîç GOOGLE TRENDS ANAL√ùZA:")
        print(f"   Patenty na spracovanie: {total}")
        print(f"   Batch size: {batch_size}")
        print(f"   Delay medzi d√°vkami: {delay_between_batches}s")
        print(f"   Odhadovan√Ω ƒças: {(total / batch_size * delay_between_batches) / 60:.1f} min\n")
        
        results = []
        
        for i in range(0, total, batch_size):
            batch_num = i // batch_size + 1
            total_batches = (total - 1) // batch_size + 1
            
            batch = patents_df.iloc[i:i+batch_size]
            print(f"   üì¶ Batch {batch_num}/{total_batches} ({len(batch)} patentov)...")
            
            for idx, row in batch.iterrows():
                result = self.analyze_patent(row[title_col])
                
                results.append({
                    'index': idx,
                    'Google_Trends_Score': result['final_score'],
                    'Google_Trends_Keyword': result['keyword'],
                    'Google_Trends_Direction': result['trend_direction'],
                    'Google_Trends_Avg_Interest': result['avg_interest']
                })
            
            # Pauza medzi d√°vkami (okrem poslednej)
            if i + batch_size < total:
                print(f"   ‚è≥ Pauza {delay_between_batches}s (rate limiting)...")
                time.sleep(delay_between_batches)
        
        print(f"\n‚úì Google Trends anal√Ωza dokonƒçen√°!")
        
        # Merge v√Ωsledkov
        results_df = pd.DataFrame(results).set_index('index')
        return patents_df.join(results_df)


# =============================================================================
# TESTOVANIE
# =============================================================================

if __name__ == "__main__":
    """Jednoduch√Ω test"""
    
    analyzer = GoogleTrendsAnalyzer()
    
    # Test 1: Jeden patent
    print("=" * 60)
    print("TEST: Anal√Ωza jedn√©ho patentu")
    print("=" * 60)
    
    result = analyzer.analyze_patent(
        title="Machine Learning Classification Method",
        abstract="A method for classifying data..."
    )
    
    print(f"Keyword: {result['keyword']}")
    print(f"Avg Interest: {result['avg_interest']:.2f}/100")
    print(f"Direction: {result['trend_direction']}")
    print(f"Final Score: {result['final_score']:.3f}")
    
    # Test 2: Batch
    print("\n" + "=" * 60)
    print("TEST: Batch anal√Ωza")
    print("=" * 60)
    
    test_df = pd.DataFrame({
        'Title': [
            'Artificial Intelligence System',
            'Solar Panel Efficiency',
            'Battery Storage Technology'
        ]
    })
    
    result_df = analyzer.batch_analyze(
        test_df, 
        title_col='Title',
        batch_size=2,
        delay_between_batches=5  # Kr√°tka pauza pre test
    )
    
    print("\nV√Ωsledky:")
    print(result_df[['Title', 'Google_Trends_Score', 'Google_Trends_Direction']])